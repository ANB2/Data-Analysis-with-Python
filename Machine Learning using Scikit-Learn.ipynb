{
 "metadata": {
  "name": "Machine Learning using Scikit-Learn"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Machine learning overview\n",
      "Machine learning is to develop algorithms that make decisions using a model fitted on data.\n",
      "\n",
      "The goal is to build a model which makes decisions automatically\n",
      "based on new information, whose performance\n",
      "improves with experience. Initially train the model with a subset of the input.\n",
      "\n",
      "- [Scikit-Learn Documentation](http://scikit-learn.org/dev/)\n",
      "\n",
      "### Scikit-Learn\n",
      "scikit-learn package is a collection of machine learning algorithms\n",
      "which share this common usage pattern:\n",
      "\n",
      "- Load data\n",
      "- Pick model\n",
      "- Fit model parameters to data\n",
      "- Predict using fitted model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets, neighbors\n",
      "iris = datasets.load_iris()\n",
      "model = neighbors.KNeighborsClassifier()\n",
      "model.fit(iris.data, iris.target)\n",
      "model.predict([7.5, 3, 6.5, 2.1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "array([2])"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- [Scikit-Learn Tutorials](http://scikit-learn.org/dev)\n",
      "- [Scikit-Learn Examples](http://scikit-learn.org/dev/auto_examples)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Cut & paste code from gallery and press CTRL-ENTER"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Cut & paste code from an example and press CTRL-ENTER "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Which model do we use?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_digits\n",
      "digits = load_digits()\n",
      "X, y = digits.data, digits.target\n",
      "trainingSet = X[:-100], y[:-100]\n",
      "testSet = X[-100:], y[-100:]\n",
      "\n",
      "def evaluate_model(model):\n",
      "    return model.fit(*trainingSet).score(*testSet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named sklearn.datasets",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-cd1b74441d48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainingSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtestSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named sklearn.datasets"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.gaussian_process import GaussianProcess\n",
      "evaluate_model(GaussianProcess())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "0.74548917199754894"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "evaluate_model(SVC(kernel='linear', C=0.001))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "0.98999999999999999"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Evaluate model performance with [cross-validation](http://scikit-learn.org/dev/model_selection.html)\n",
      "\n",
      "###cross-validation: \n",
      "Is a model validation technique for assessing how the results of a statistical analysis will generalize to an independent data set\n",
      "\n",
      "Mainly used in settings where the goal is prediction, and one wants to estimate how accurately a predictive model will perform in practice. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "iris = load_iris()\n",
      "model = LogisticRegression()\n",
      "\n",
      "# Array of scores of the estimator for each run of the cross validation.\n",
      "cross_val_score(model, iris.data, iris.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(model, iris.data, iris.target, cv=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import LeaveOneOut\n",
      "\n",
      "cross_val_score(model, iris.data, iris.target, cv=LeaveOneOut(len(iris.target)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Evaluate stack performance with [pipelining](http://scikit-learn.org/dev/modules/pipeline.html)\n",
      "\n",
      "### Pipelining\n",
      "Chain multiple estimators into one. \n",
      "\n",
      "Useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.lib.display import YouTubeVideo\n",
      "YouTubeVideo('1uS5b8aQ6z8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.datasets import load_digits; digits = load_digits()\n",
      "\n",
      "model = Pipeline([\n",
      "    ('pca', PCA()), \n",
      "    ('logistic', LogisticRegression()),\n",
      "])\n",
      "np.mean(cross_val_score(model, digits.data, digits.target))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### [Transform](http://scikit-learn.org/dev/data_transforms.html) data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "# StandardScaler: Standardize features by removing the mean and scaling to unit variance\n",
      "# Principal component analysis: Linear dimensionality reduction using Singular Value Decomposition of the data and keeping only the most \n",
      "#     significant singular vectors to project the data to a lower dimensional space.\n",
      "\n",
      "# Logistic Regression: used for predicting the outcome of a categorical dependent variable (a dependent variable that can take on a \n",
      "#     limited number of values, whose magnitudes are not meaningful but whose ordering of magnitudes may or may not be meaningful) \n",
      "#     based on one or more predictor variables\n",
      "\n",
      "model = Pipeline([\n",
      "    ('scaler', StandardScaler()),\n",
      "    ('pca', PCA()), \n",
      "    ('logistic', LogisticRegression()),\n",
      "])\n",
      "np.mean(cross_val_score(model, digits.data, digits.target))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "vectorizer = CountVectorizer(min_df=1)\n",
      "documents = [\n",
      "    'my imagination',\n",
      "    'is a piece of board',\n",
      "    'my sole instrument',\n",
      "    'is a wooden stick',\n",
      "]\n",
      "X = vectorizer.fit_transform(documents)\n",
      "documentVectors = X.toarray()\n",
      "documentVectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named sklearn.feature_extraction.text",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-d54dc3147374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m documents = [\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'my imagination'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named sklearn.feature_extraction.text"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featureNames = vectorizer.get_feature_names()\n",
      "for bagOfWords in documentVectors:\n",
      "    print zip(featureNames, bagOfWords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'vectorizer' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-8483783d4998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatureNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbagOfWords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocumentVectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbagOfWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Identify a translator of Lady Gaga"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from archiveIO import Archive, TemporaryFolder\n",
      "\n",
      "archive = Archive('data/ladygaga.tar.gz')\n",
      "documents = []\n",
      "categories = []\n",
      "with TemporaryFolder() as temporaryFolder:\n",
      "    for documentPath in archive.load(temporaryFolder):\n",
      "        text = open(documentPath).read()\n",
      "        documents.append(text)\n",
      "        categories.append('lady' in text)\n",
      "        \n",
      "print categories"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[True, True, True, True]\n"
       ]
      }
     ],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}